<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://muelea.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://muelea.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-20T14:44:26+00:00</updated><id>https://muelea.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Could body shape determine the German election?</title><link href="https://muelea.github.io/blog/2021/body_shape/" rel="alternate" type="text/html" title="Could body shape determine the German election?"/><published>2021-09-05T00:00:00+00:00</published><updated>2021-09-05T00:00:00+00:00</updated><id>https://muelea.github.io/blog/2021/body_shape</id><content type="html" xml:base="https://muelea.github.io/blog/2021/body_shape/"><![CDATA[]]></content><author><name></name></author><category term="bodyshape"/><category term="shapebias"/><summary type="html"><![CDATA[Biases in body shape perception unveiled for the 2021 German election candidates]]></summary></entry><entry><title type="html">Touch in human mesh reconstruction.</title><link href="https://muelea.github.io/blog/2021/touch/" rel="alternate" type="text/html" title="Touch in human mesh reconstruction."/><published>2021-09-05T00:00:00+00:00</published><updated>2021-09-05T00:00:00+00:00</updated><id>https://muelea.github.io/blog/2021/touch</id><content type="html" xml:base="https://muelea.github.io/blog/2021/touch/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/pexels-tiana-951572-480.webp 480w,/assets/img/blog/pexels-tiana-951572-800.webp 800w,/assets/img/blog/pexels-tiana-951572-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/pexels-tiana-951572.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div style="margin-top: 40px;"></div> <div style="text-align: justify;"> <p>The human skin is designed to experience touch -- the ability to perceive a stimulus that comes into contact with the body surface. The sense of touch is crucial because it allows us to experience physical sensations, create and deepen social relationships, and establish a connection with the world around us. The field of computer vision should be able to model and reconstruct the full human body surface and capture its complex interactions with ourselves, other humans, and the environment. Understanding contact through computer vision will enable advancements in virtual and augmented reality and impact other fields like robotics and behavioral science. Interestingly, many works in our field investigate interaction between humans and scenes, while research on self- and human-human contact remains relatively scarce in comparison.</p> <p>Human beings engage in self-touch or self-contact multiple times a day, indicating its behavioral significance and prompting extensive research in behavioral- and neuroscience. For instance, studies have shown that facial self-touch is a recognized indicator of stress in adults <a class="citation" href="#densing2018effect">(Densing et al., 2018)</a>. Infants frequently and spontaneously touch their own body, which serves as a way of exploration, facilitating the development of body awareness <a class="citation" href="#khoury2022selftouch">(Khoury et al., 2022)</a> and even fetuses show increased self-contact when maternal stress is present <a class="citation" href="#reissland2015laterality">(Reissland et al., 2015)</a>. The patterns of self-touch are manifold as they vary in speed, trajectory, or movement duration <a class="citation" href="#barroso1980self">(Barroso et al., 1980; Lausberg, 2013)</a> and their exact function is still unknown. Some work argues that self-touch mainly serves for self-stabilization and self-calming <a class="citation" href="#lausberg2013understanding">(Lausberg, 2013; Scherer &amp; Wallbott, 1979)</a> or as a mechanism for down-regulation in high arousal states <a class="citation" href="#scherer1979nonverbale">(Scherer &amp; Wallbott, 1979)</a>. Self-touch is also associated with emotional processes that interfere with working memory performance <a class="citation" href="#grunwald2014eeg">(Grunwald et al., 2014)</a>. In particular, suppressing self-touch among individuals who frequently touch their own body leads to significantly worse memory performance in haptic working memory tasks <a class="citation" href="#spille2022suppression">(Spille et al., 2022)</a>. Other research indicates a connection between different patterns of self-touch and neuropsychological state <a class="citation" href="#barroso1980self">(Barroso et al., 1980; Thompson, 2010)</a> and mental arousal <a class="citation" href="#kryger2010bewegungsverhalten">(Kryger, 2010; Lausberg &amp; Kryger, 2011; Ulrich &amp; Harms, 1985)</a>. In dialogues, self-touching colloquists are rated significantly more honest, outgoing, likable, and positively w.r.t. the working relationship compared to their non self-touching equivalent <a class="citation" href="#harrigan1987self">(Harrigan et al., 1987)</a>. This indicates a relevance of self-touch not only for self-regulation but also as an outwardly effective mechanism.</p> <p>The relevance of interpersonal touch or human-human contact has also been investigated extensively in behavioral science, in particular the role of social touch <a class="citation" href="#saarinen2021social">(Saarinen et al., 2021)</a>. In fact, the body of research on social touch is extensive, and this paragraph can only offer a brief glimpse into interpersonal touch to highlight its relevance and functionality in human behavior. Beginning from early childhood, physical contact between parent and child establishes bonds and is associated with immediate stress reduction <a class="citation" href="#stack1990tactile">(Stack &amp; Muir, 1990; Feldman et al., 2010)</a>, enhanced object exploration <a class="citation" href="#tanaka2021social">(Tanaka et al., 2021)</a>, and long-term effects on behaviour <a class="citation" href="#bai2016children">(Bai et al., 2016; Pickles et al., 2017; Cascio et al., 2019)</a>. Early vocabulary items may consist of words often linked with caregiver touches <a class="citation" href="#seidl2015body">(Seidl et al., 2015)</a>. This is surprising because there is no reason why words like 'feet' should be spoken more often than 'diaper'. In older children, the avoidance of interpersonal touch can be a predictor of autism spectrum disorder <a class="citation" href="#baranek1999autism">(Baranek, 1999; Mammen et al., 2015)</a>. Social touch also has many effects in adulthood. Crusco and Wetzel <a class="citation" href="#crusco1984midas">(Crusco &amp; Wetzel, 1984)</a> show that a slight touch increased tips in restaurants, i.e. touch causes a more friendly behaviour towards the touch-giver. This effect, also known as the Midas touch, was replicated multiple times in subseqeunt research studies. For example, the exposure to social touch increases a bus driver’s willingness to transport customers without having enough money for the ticket <a class="citation" href="#gueguen2003another">(Guéguen &amp; Fischer-Lokou, 2003)</a>. Recent work found that, in virtual reality, agents with touch are perceived as more human-like <a class="citation" href="#hoppe2020human">(Hoppe et al., 2020)</a>. This confirms the importance of touch not only in real life but also in the virtual world.</p> <p>Despite the great relevance of self- and human-human contact to learn about human behavior and states, most research on this topic is constrained by small group sizes because contact usually requires manual annotation as only a few rudimentary detection and reconstruction methods exist. This prevents understanding the importance and functionality of touch on human behavior at scale. The field of computer vision could advance the understanding of human social interactions by providing methods for 3D mesh reconstruction with accurate self- and mutual contact from images and video.</p> <p>Unfortunately, self- and human-human contact has rarely been studied. One reason is that contact is rare in most human scan and motion capture (Mo. Cap.) datasets, because contact naturally leads to occlusion, which hampers data capturing. In body scan datasets, most poses avoid self-contact and in Mo. Cap. systems usually only a single person is captured. The implications for our field are evident: recent 3D motion generation methods can perfectly synthesize a single static person <a class="citation" href="#hassan2019prox">(Hassan et al., 2019; Zhang et al., 2020; Hassan et al., 2021; Zhao et al., 2022)</a> or human motion <a class="citation" href="#hassan2021samp">(Hassan et al., 2021; Wang et al., 2022; Zhang &amp; Tang, 2022; Hassan et al., 2023; Mir et al., 2023; Huang et al., 2023)</a>, but can not generate two people shaking hands. Another reason why reconstructing accuracte contact is neglected in 3D human pose and shape estimation is that most methods predominantly rely on 2D joint locations for supervision. However, 2D joints are not sufficient to accurately estimate the body surface, because one set of 2D joints can be explained by multiple body shapes and also by multiple poses when no ground-truth camera information is available. Priors, i.e. mathematical functions or models that incorporate prior knowledge about human pose and shape, are usually learned from scan and Mo. Cap. datasets that hardly contain contact poses. This leads to 3D mesh estimates that, when projected onto the image, satisfy reprojection constraints and may perfectly overlay with the image evidence. A rotation to the side, however, reveals that the estimated poses are not correct. </p> <p> Being able to reconstruct and generate meshes with self- and mutual contact will facilitate the creation of avatars aligned with human behaviour which will let them appear more human-like, natural, and realistic. </p> </div>]]></content><author><name></name></author><category term="touch"/><summary type="html"><![CDATA[An article to motivate computer vision researchers to study self- and human-to-human contact by highlighting the manifold impact of touch on human behavior.]]></summary></entry></feed>