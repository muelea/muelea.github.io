---
layout: post
title: Touch in human mesh reconstruction.
date: 2021-09-05 00:00:00
description: An article to motivate computer vision researchers to study self- and human-to-human contact by highlighting the manifold impact of touch on human behavior.
tags: touch
related_publications: true
---

{% include figure.liquid loading="eager" path="assets/img/blog/pexels-tiana-951572.jpg" class="img-fluid rounded z-depth-1" %}

<div style="margin-top: 40px;"></div>
<div style="text-align: justify;">
<p>The human skin is designed to experience touch -- the ability to perceive a stimulus that comes into contact with the body surface. The sense of touch is crucial because it allows us to experience physical sensations, create and deepen social relationships, and establish a connection with the world around us. The field of computer vision should be able to model and reconstruct the full human body surface and capture its complex interactions with ourselves, other humans, and the environment. Understanding contact through computer vision will enable advancements in virtual and augmented reality and impact other fields like robotics and behavioral science. Interestingly, many works in our field investigate interaction between humans and scenes, while research on self- and human-human contact remains relatively scarce in comparison.</p>

<p>Human beings engage in self-touch or self-contact multiple times a day, indicating its behavioral significance and prompting extensive research in behavioral- and neuroscience. For instance, studies have shown that facial self-touch is a recognized indicator of stress in adults {% cite densing2018effect %}. Infants frequently and spontaneously touch their own body, which serves as a way of exploration, facilitating the development of body awareness {% cite khoury2022selftouch %} and even fetuses show increased self-contact when maternal stress is present {% cite reissland2015laterality %}. The patterns of self-touch are manifold as they vary in speed, trajectory, or movement duration {% cite barroso1980self lausberg2013understanding %} and their exact function is still unknown. Some work argues that self-touch mainly serves for self-stabilization and self-calming {% cite lausberg2013understanding scherer1979nonverbale %} or as a mechanism for down-regulation in high arousal states {% cite scherer1979nonverbale %}. Self-touch is also associated with emotional processes that interfere with working memory performance {% cite grunwald2014eeg %}. In particular, suppressing self-touch among individuals who frequently touch their own body leads to significantly worse memory performance in haptic working memory tasks {% cite spille2022suppression %}. Other research indicates a connection between different patterns of self-touch and neuropsychological state {% cite barroso1980self thompson2010grooming %} and mental arousal {% cite kryger2010bewegungsverhalten lausberg2011gestisches ulrich1985video %}. In dialogues, self-touching colloquists are rated significantly more honest, outgoing, likable, and positively w.r.t. the working relationship compared to their non self-touching equivalent {% cite harrigan1987self %}. This indicates a relevance of self-touch not only for self-regulation but also as an outwardly effective mechanism.</p>

<p>The relevance of interpersonal touch or human-human contact has also been investigated extensively in behavioral science, in particular the role of social touch {% cite saarinen2021social %}. In fact, the body of research on social touch is extensive, and this paragraph can only offer a brief glimpse into interpersonal touch to highlight its relevance and functionality in human behavior. Beginning from early childhood, physical contact between parent and child establishes bonds and is associated with immediate stress reduction {% cite stack1990tactile feldman2010touch %}, enhanced object exploration {% cite tanaka2021social %}, and long-term effects on behaviour {% cite bai2016children pickles2017prenatal cascio2019social %}. Early vocabulary items may consist of words often linked with caregiver touches {% cite seidl2015body %}. This is surprising because there is no reason why words like 'feet' should be spoken more often than 'diaper'. In older children, the avoidance of interpersonal touch can be a predictor of autism spectrum disorder {% cite baranek1999autism mammen2015infant %}. Social touch also has many effects  in adulthood. Crusco and Wetzel {% cite crusco1984midas %} show that a slight touch increased tips in restaurants, i.e. touch causes a more friendly behaviour towards the touch-giver. This effect, also known as the Midas touch, was replicated multiple times in subseqeunt research studies. For example, the exposure to social touch increases a bus driverâ€™s willingness to transport customers without having enough money for the ticket {% cite gueguen2003another %}. Recent work found that, in virtual reality, agents with touch are perceived as more human-like {% cite hoppe2020human %}. This confirms the importance of touch not only in real life but also in the virtual world.</p>

<p>Despite the great relevance of self- and human-human contact to learn about human behavior and states, most research on this topic is constrained by small group sizes because contact usually requires manual annotation as only a few rudimentary detection and reconstruction methods exist. This prevents understanding the importance and functionality of touch on human behavior at scale. The field of computer vision could advance the understanding of human social interactions by providing methods for 3D mesh reconstruction with accurate self- and mutual contact from images and video.</p>

<p>Unfortunately, self- and human-human contact has rarely been studied. One reason is that contact is rare in most human scan and motion capture (Mo. Cap.) datasets, because contact naturally leads to occlusion, which hampers data capturing. In body scan datasets, most poses avoid self-contact and in Mo. Cap. systems usually only a single person is captured. The implications for our field are evident: recent 3D motion generation methods can perfectly synthesize a single static person {% cite hassan2019prox zhang2019generating hassan2021populating zhao2022compositional %} or human motion {% cite hassan2021samp wang2022humanise zhang2022wanderings hassan2023synthesizing mir2023origin huang2023diffusion %}, but can not generate two people shaking hands. Another reason why reconstructing accuracte contact is neglected in 3D human pose and shape estimation is that most methods predominantly rely on 2D joint locations for supervision. However, 2D joints are not sufficient to accurately estimate the body surface, because one set of 2D joints can be explained by multiple body shapes and also by multiple poses when no ground-truth camera information is available. Priors, i.e. mathematical functions or models that incorporate prior knowledge about human pose and shape, are usually learned from scan and Mo. Cap. datasets that hardly contain contact poses. This leads to 3D mesh estimates that, when projected onto the image, satisfy reprojection constraints and may perfectly overlay with the image evidence. A rotation to the side, however, reveals that the estimated poses are not correct. </p>

<p> Being able to reconstruct and generate meshes with self- and mutual contact will facilitate the creation of avatars aligned with human behaviour which will let them appear more human-like, natural, and realistic. </p>
